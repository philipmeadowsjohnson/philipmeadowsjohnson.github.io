"use strict";(self.webpackChunkPhilipMeadowsJohnson=self.webpackChunkPhilipMeadowsJohnson||[]).push([[501],{3905:function(e,t,s){s.d(t,{Zo:function(){return p},kt:function(){return f}});var n=s(7294);function i(e,t,s){return t in e?Object.defineProperty(e,t,{value:s,enumerable:!0,configurable:!0,writable:!0}):e[t]=s,e}function r(e,t){var s=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),s.push.apply(s,n)}return s}function o(e){for(var t=1;t<arguments.length;t++){var s=null!=arguments[t]?arguments[t]:{};t%2?r(Object(s),!0).forEach((function(t){i(e,t,s[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(s)):r(Object(s)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(s,t))}))}return e}function a(e,t){if(null==e)return{};var s,n,i=function(e,t){if(null==e)return{};var s,n,i={},r=Object.keys(e);for(n=0;n<r.length;n++)s=r[n],t.indexOf(s)>=0||(i[s]=e[s]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)s=r[n],t.indexOf(s)>=0||Object.prototype.propertyIsEnumerable.call(e,s)&&(i[s]=e[s])}return i}var c=n.createContext({}),l=function(e){var t=n.useContext(c),s=t;return e&&(s="function"==typeof e?e(t):o(o({},t),e)),s},p=function(e){var t=l(e.components);return n.createElement(c.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var s=e.components,i=e.mdxType,r=e.originalType,c=e.parentName,p=a(e,["components","mdxType","originalType","parentName"]),d=l(s),f=i,h=d["".concat(c,".").concat(f)]||d[f]||u[f]||r;return s?n.createElement(h,o(o({ref:t},p),{},{components:s})):n.createElement(h,o({ref:t},p))}));function f(e,t){var s=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=s.length,o=new Array(r);o[0]=d;var a={};for(var c in t)hasOwnProperty.call(t,c)&&(a[c]=t[c]);a.originalType=e,a.mdxType="string"==typeof e?e:i,o[1]=a;for(var l=2;l<r;l++)o[l]=s[l];return n.createElement.apply(null,o)}return n.createElement.apply(null,s)}d.displayName="MDXCreateElement"},9880:function(e,t,s){s.r(t),s.d(t,{frontMatter:function(){return a},contentTitle:function(){return c},metadata:function(){return l},toc:function(){return p},default:function(){return d}});var n=s(7462),i=s(3366),r=(s(7294),s(3905)),o=["components"],a={title:"Developing processListings()"},c=void 0,l={unversionedId:"developers/process-listings",id:"developers/process-listings",isDocsHomePage:!1,title:"Developing processListings()",description:"Motivation",source:"@site/docs/developers/process-listings.md",sourceDirName:"developers",slug:"/developers/process-listings",permalink:"/docs/developers/process-listings",tags:[],version:"current",frontMatter:{title:"Developing processListings()"},sidebar:"someSidebar",previous:{title:"Basic Invocation",permalink:"/docs/developers/invocation"},next:{title:"Implementation",permalink:"/docs/developers/implementation"}},p=[{value:"Motivation",id:"motivation",children:[],level:2},{value:"Workflow",id:"workflow",children:[{value:"1. Run the scraper, and generate the &quot;unprocessed&quot; Listings file.",id:"1-run-the-scraper-and-generate-the-unprocessed-listings-file",children:[],level:3},{value:"2. Determine what you want to &quot;process&quot;",id:"2-determine-what-you-want-to-process",children:[],level:3},{value:"3. Make a copy of the &quot;unprocessed&quot; listings file",id:"3-make-a-copy-of-the-unprocessed-listings-file",children:[],level:3},{value:"4. Implement your initial version of processListings()",id:"4-implement-your-initial-version-of-processlistings",children:[],level:3},{value:"5. Run the scrape script as many times as necessary with --process-listings-file",id:"5-run-the-scrape-script-as-many-times-as-necessary-with---process-listings-file",children:[],level:3},{value:"6. Run your scraper one last time to verify processListings()",id:"6-run-your-scraper-one-last-time-to-verify-processlistings",children:[],level:3}],level:2}],u={toc:p};function d(e){var t=e.components,s=(0,i.Z)(e,o);return(0,r.kt)("wrapper",(0,n.Z)({},u,s,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"motivation"},"Motivation"),(0,r.kt)("p",null,"The standard scraper workflow involves:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"generateListings(): scrape the website and create a single Listings object containing a set of Listing objects."),(0,r.kt)("li",{parentName:"ul"},'processListings(): run through the individual Listing objects and improve them. For example, replace non-breaking space characters by regular spaces, or reduce 4 newlines to 2, or filter listings that don\'t contain "Computer Science" or other important keywords.')),(0,r.kt)("p",null,"This workflow is problematic during development. Let's say it takes 30 minutes for generateListings() to scrape the site.  It is frustrating to have to wait 30 minutes each time you want to test out a minor change to processListings()."),(0,r.kt)("p",null,"To simplify development of processListings(), the scrape script includes a ",(0,r.kt)("inlineCode",{parentName:"p"},"--process-listings-file")," option, which takes a file name as its value. When this option is provided, the script does not invoke generateListings(), but instead initializes the Listings object directly from the passed file.  This enables you to repeatedly run and refine the processListings() method without having to re-scrape the site each time."),(0,r.kt)("h2",{id:"workflow"},"Workflow"),(0,r.kt)("p",null,"Here is how to use the --process-listings-file option to support development of the processListings() method."),(0,r.kt)("h3",{id:"1-run-the-scraper-and-generate-the-unprocessed-listings-file"},'1. Run the scraper, and generate the "unprocessed" Listings file.'),(0,r.kt)("p",null,"To start, run your chosen scraper to generate its listings file. It's best to comment out the processListings() method at this point, so the generated listings file does not contain any post-processing."),(0,r.kt)("p",null,"For example, let's assume we are developing the processListings() method for the NSF scraper. We can start by running the scraper without an NSF-specific processListings() method:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ npm run scrape -- -s nsf\n\n> scraper@2.0.0 scrape\n> ts-node -P tsconfig.buildScripts.json scrape.ts "-s" "nsf"\n\n12:39:32 WARN NSF Launching NSF scraper\n12:39:37 INFO NSF Wrote 100 listings to ./listings/compsci/nsf.dev.json.\n12:39:37 INFO NSF Wrote statistics.\n')),(0,r.kt)("h3",{id:"2-determine-what-you-want-to-process"},'2. Determine what you want to "process"'),(0,r.kt)("p",null,"When we examine at the Listings file (nsf.dev.json), we notice the following:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},' "description": "Research Topics/Keywords: ..\n')),(0,r.kt)("p",null,'Let\'s say we actually want the description field to say "Research Topics and Keywords". So, we need a processListings() method to fix the description field.'),(0,r.kt)("h3",{id:"3-make-a-copy-of-the-unprocessed-listings-file"},'3. Make a copy of the "unprocessed" listings file'),(0,r.kt)("p",null,"The next step is to make a copy of the unprocessed listings file:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ cp nsf.dev.json nsf.test.dev.json\n")),(0,r.kt)("h3",{id:"4-implement-your-initial-version-of-processlistings"},"4. Implement your initial version of processListings()"),(0,r.kt)("p",null,"Now start the implementation of your processListings() method. For example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-js"},"fixDescription(description) {\n  return description.replace('Research Topics/Keywords', ' Research Topics and Keywords');\n}\n\nasync processListings() {\n  await super.processListings();\n  this.listings.forEach(listing => { listing.description = this.fixDescription(listing.description); });\n}\n")),(0,r.kt)("h3",{id:"5-run-the-scrape-script-as-many-times-as-necessary-with---process-listings-file"},"5. Run the scrape script as many times as necessary with --process-listings-file"),(0,r.kt)("p",null,"Now run your scraper, passing your test file as the argument to --process-listings-file. For example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ npm run scrape -- -s nsf --process-listings-file nsf.test.dev.json\n\n> scraper@2.0.0 scrape\n> ts-node -P tsconfig.buildScripts.json scrape.ts "-s" "nsf" "--process-listings-file" "nsf.test.dev.json"\n\n12:54:47 WARN NSF Launching NSF scraper\n12:54:47 INFO NSF Reading listings from ./listings/compsci/nsf.test.dev.json\n12:54:47 INFO NSF Wrote 100 listings to ./listings/compsci/nsf.dev.json.\n12:54:47 INFO NSF Wrote statistics.\n')),(0,r.kt)("p",null,"This script reads in listings from nsf.test.dev.json, initializes the Listings object in the NSF scraper with that data, skips over generateListings(), then calls processListings() and writes out the results."),(0,r.kt)("p",null,'You can now compare the contents of your "test" file (nsf.test.dev.json) to the file written after calling processListings() (nsf.dev.json).  If it\'s not correct, just edit your processListings() code and rerun the above command.  The "test" file is not changed by this command, so you don\'t have to regenerate it.'),(0,r.kt)("p",null,"Keep rerunning this command until your processListings() code produces a Listings file the way that you want it."),(0,r.kt)("p",null,"In this example, we inspect the nsf.dev.json file and notice that our description field is now the way we want it:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},' "description": " Research Topics and Keywords:\n')),(0,r.kt)("h3",{id:"6-run-your-scraper-one-last-time-to-verify-processlistings"},"6. Run your scraper one last time to verify processListings()"),(0,r.kt)("p",null,"Before committing your code, you might want to run your scraper a final time to ensure that processListings() is working correctly:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'$ npm run scrape -- -s nsf\n\n> scraper@2.0.0 scrape\n> ts-node -P tsconfig.buildScripts.json scrape.ts "-s" "nsf"\n\n13:02:02 WARN NSF Launching NSF scraper\n13:02:09 INFO NSF Wrote 100 listings to ./listings/compsci/nsf.dev.json.\n13:02:09 INFO NSF Wrote statistics.\n')))}d.isMDXComponent=!0}}]);